{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from charset_normalizer import from_path  # エンコーディング自動検出用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTMLファイルが格納されているディレクトリのパス\n",
    "directory = \"www.geocities.co.jp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_html(file_path):\n",
    "    \"\"\"\n",
    "    HTMLファイルからテキストを抽出する関数\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # charset-normalizerを使ってファイルを自動的に読み込む\n",
    "        result = from_path(file_path).best()\n",
    "        content = str(result)  # decodeの代わりにstr()で文字列に変換\n",
    "        soup = BeautifulSoup(content, 'html.parser')\n",
    "        return soup.get_text(separator='\\n')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None  # エラーが発生した場合、空のテキストを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_recursive_to_df(directory, max_pages=100):\n",
    "    \"\"\"\n",
    "    指定されたディレクトリを再帰的に検索し、HTMLファイルからテキストを抽出し、\n",
    "    ディレクトリ構造をキーとしてDataFrameに格納する関数\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    page_count = 0\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".html\") or file.endswith(\".htm\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                text = \"\".join(extract_text_from_html(file_path))\n",
    "                if text is None: continue\n",
    "                # ディレクトリ構造と抽出したテキストをDataFrameに格納するためリストに追加\n",
    "                data.append({\"directory\": root + \"_\".join(dirs), \"file\": file, \"text\": text[:500]})  # 500文字のみ格納\n",
    "                \n",
    "                page_count += 1\n",
    "                if page_count >= max_pages:\n",
    "                    print(f\"Processed {max_pages} pages. Stopping...\")\n",
    "                    return pd.DataFrame(data)  # DataFrameに変換して返す\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 pages. Stopping...\n",
      "                                           directory           file  \\\n",
      "0  www.geocities.co.jp/Playtown-Domino/6517gagaga...   geobook.html   \n",
      "1  www.geocities.co.jp/Playtown-Domino/6517gagaga...  seltutei.html   \n",
      "2  www.geocities.co.jp/Playtown-Domino/6517gagaga...    ninjya.html   \n",
      "3  www.geocities.co.jp/Playtown-Domino/6517gagaga...     index.html   \n",
      "4  www.geocities.co.jp/Playtown-Domino/6517gagaga...  geodiary.html   \n",
      "\n",
      "                                                text  \n",
      "0  \\n\\n\\n\\nGGGゲストブック\\n\\n\\n\\n\\n\\n\\n\\n\\n僕のゲストブックです、...  \n",
      "1  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n特捜勇者\\n\\n\\n\\n\\n\\n\\n...  \n",
      "2  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n第1話\\n\\n\\n\\n\\n\\n\\n\\...  \n",
      "3  \\n\\n\\n\\n\\n\\n\\n\\nＧＧＧ奈良支部ドラえもん課\\n\\n\\n\\n\\n\\n\\n\\n\\...  \n",
      "4  \\n\\n\\n\\n我王神地のプラモデル日記\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...  \n"
     ]
    }
   ],
   "source": [
    "# 実行\n",
    "df = extract_text_recursive_to_df(directory)\n",
    "\n",
    "# データフレームを表示\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
